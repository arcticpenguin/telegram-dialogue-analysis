{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import helper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baidu_AK = \n",
    "baidu_SK = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib,sys\n",
    "import ssl\n",
    "\n",
    "# client_id 为官网获取的AK， client_secret 为官网获取的SK\n",
    "host = 'https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id=%s&client_secret=%s' %(baidu_AK, baidu_SK)\n",
    "print(host)\n",
    "request = urllib.request.Request(host)\n",
    "request.add_header('Content-Type', 'application/json; charset=UTF-8')\n",
    "response = urllib.request.urlopen(request)\n",
    "content = response.read()\n",
    "if (content):\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict(\"user_dict.txt\")\n",
    "\n",
    "def preprocessText(x):\n",
    "    #@todo regex to handle ..., ???, etc\n",
    "    x = re.sub(r'(。(。*)。)', ' threePeriodsMark ', x)\n",
    "    x = re.sub(r'(\\?(\\?*)\\?)|(？(？*)？)', \" threeQuestionsMark \", x)\n",
    "    x = re.sub(r'(啊(\\啊*)啊)', \" threeAHsMark \", x)\n",
    "    x = re.sub(r'(嗷(\\嗷*)嗷)', \" threeAOsMark \", x)\n",
    "    x = re.sub(r'(嗯(\\嗯*)嗯)', \" threeENsMark \", x)\n",
    "    x = re.sub(r'(哈(\\哈*)哈)', \" threeHAsMark \", x)\n",
    "    x = re.sub(r'(喔(\\喔*)喔)', \" threeWOsMark \", x)\n",
    "    x = x.replace(\">_<\",\" emojiMengbi \")\n",
    "    x = re.sub(r\"(。|，|\\,)\",\" \",x)\n",
    "    return x\n",
    "\n",
    "def cut_word(x):\n",
    "    p_x = preprocessText(x)\n",
    "#     print (p_x)\n",
    "    seg_list = [word for word in jieba.cut(p_x, cut_all=False) if word != \" \"]\n",
    "    return seg_list\n",
    "\n",
    "print(cut_word(\"我爱北京天安门\"))\n",
    "print(cut_word(\"you are my star\"))\n",
    "print(cut_word(\"我不会java\"))\n",
    "print(cut_word(\"\"))\n",
    "print(cut_word(\"我们中出了，一个叛徒\"))\n",
    "print(cut_word(\"。。。\"))\n",
    "print(cut_word(\"a。。。。b\"))\n",
    "print(cut_word(\"。。\"))\n",
    "print(cut_word(\"...\"))\n",
    "print(cut_word(\"?\"))\n",
    "print(cut_word(\"我们.\"))\n",
    "print(cut_word(\"嗯哼\"))\n",
    "print(cut_word(\"啊嘞????\"))\n",
    "print(cut_word(\"我擦嘞\"))\n",
    "print(cut_word(\"我嗷嗷\"))\n",
    "print(cut_word(\"哈哈\"))\n",
    "print(cut_word(\"我去\"))\n",
    "print(cut_word(\"我去北京上学\"))\n",
    "print(cut_word(\"我去北京上学, nnsd\"))\n",
    "print(cut_word(\"我靠\"))\n",
    "print(cut_word(\">_<\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df[\"text_cut\"] = df[\"text\"].apply(lambda x: cut_word(x) if not pd.isnull(x) else [])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = helper.load_data(small=False)\n",
    "df = preprocessing(df)\n",
    "# df.to_csv(\"fullData_cutted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = helper.load_data(small=True)\n",
    "df = preprocessing(df)\n",
    "# df.to_csv(\"smallData_cutted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnestCuttedWord(df):\n",
    "    df[\"text_cut_num\"] = df[\"text_cut\"].apply(lambda x: len(x) if x else 0)\n",
    "    idColumn = df[\"id\"].repeat(df[\"text_cut_num\"])\n",
    "    wordColumn = np.concatenate(df[\"text_cut\"].values)\n",
    "    return pd.DataFrame({\"id\": idColumn, \"word\": wordColumn})\n",
    "    \n",
    "wordLevelDf = pd.merge(unnestCuttedWord(df), df[[\"id\",\"from\"]], on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordLevelDf.to_csv(\"small_word_level.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "token = json.loads(content)[\"access_token\"]\n",
    "headers = {'content-type' : 'application/json'}\n",
    "baidu_sentiment_analysis_url = \"https://aip.baidubce.com/rpc/2.0/nlp/v1/sentiment_classify\"\n",
    "params = {\n",
    "    \"access_token\":token\n",
    "}\n",
    "\n",
    "def getSentiment(text):\n",
    "    post_data = {\n",
    "       \"text\": text\n",
    "    }\n",
    "    \n",
    "    if text is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(baidu_sentiment_analysis_url, params=params, data=json.dumps(post_data), headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            res = json.loads(response.text)[\"items\"][0]\n",
    "            return res\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDf = df[[\"id\",\"from\",\"date\",\"text\"]]\n",
    "cleanDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentRes = cleanDf.apply(lambda x: getSentiment(x[\"text\"]), axis = 1).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([cleanDf, sentimentRes], axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
